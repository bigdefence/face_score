{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8732548,"sourceType":"datasetVersion","datasetId":5241747}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-06-19T21:47:08.450526Z","iopub.execute_input":"2024-06-19T21:47:08.450893Z","iopub.status.idle":"2024-06-19T21:47:20.726219Z","shell.execute_reply.started":"2024-06-19T21:47:08.450864Z","shell.execute_reply":"2024-06-19T21:47:20.725289Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /opt/conda/lib/python3.10/site-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\nimport pandas as pd\nimport numpy as np\nimport os\nimport re\nimport glob\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport torchvision.models as models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom sklearn.metrics import f1_score,accuracy_score\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\nimport warnings\nimport matplotlib.pyplot as plt\nfrom PIL import Image,ImageOps\nwarnings.filterwarnings(action='ignore') \ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-19T21:47:24.385027Z","iopub.execute_input":"2024-06-19T21:47:24.385400Z","iopub.status.idle":"2024-06-19T21:47:28.534130Z","shell.execute_reply.started":"2024-06-19T21:47:24.385366Z","shell.execute_reply":"2024-06-19T21:47:28.533308Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install gdown\n!gdown --id 1uo351ez10bN24Xbs_kpfwqCSn3qiL0cn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip /kaggle/working/Images.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG = {\n    'IMG_SIZE':256,\n    'EPOCHS':10,\n    'LEARNING_RATE':1e-5,\n    'BATCH_SIZE':16,\n    'SEED':42\n}","metadata":{"execution":{"iopub.status.busy":"2024-06-19T21:47:31.141964Z","iopub.execute_input":"2024-06-19T21:47:31.142906Z","iopub.status.idle":"2024-06-19T21:47:31.147847Z","shell.execute_reply.started":"2024-06-19T21:47:31.142868Z","shell.execute_reply":"2024-06-19T21:47:31.146892Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(CFG['SEED']) # Seed 고정","metadata":{"execution":{"iopub.status.busy":"2024-06-19T21:47:33.174364Z","iopub.execute_input":"2024-06-19T21:47:33.174817Z","iopub.status.idle":"2024-06-19T21:47:33.183709Z","shell.execute_reply.started":"2024-06-19T21:47:33.174784Z","shell.execute_reply":"2024-06-19T21:47:33.182556Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/facescore-labels/All_labels.txt',sep=' ',header=None)\ndf.columns=['img_path','label']","metadata":{"execution":{"iopub.status.busy":"2024-06-19T21:47:33.980263Z","iopub.execute_input":"2024-06-19T21:47:33.980656Z","iopub.status.idle":"2024-06-19T21:47:33.997171Z","shell.execute_reply.started":"2024-06-19T21:47:33.980623Z","shell.execute_reply":"2024-06-19T21:47:33.996428Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def change_path(path):\n    path=path.replace(path,'/kaggle/working/'+path)\n    return path\ndf['img_path']=df['img_path'].apply(change_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T21:47:35.396957Z","iopub.execute_input":"2024-06-19T21:47:35.397332Z","iopub.status.idle":"2024-06-19T21:47:35.406740Z","shell.execute_reply.started":"2024-06-19T21:47:35.397303Z","shell.execute_reply":"2024-06-19T21:47:35.405656Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train,val=train_test_split(df,test_size=0.2,random_state=CFG['SEED'])","metadata":{"execution":{"iopub.status.busy":"2024-06-19T21:47:36.147869Z","iopub.execute_input":"2024-06-19T21:47:36.148511Z","iopub.status.idle":"2024-06-19T21:47:36.155986Z","shell.execute_reply.started":"2024-06-19T21:47:36.148464Z","shell.execute_reply":"2024-06-19T21:47:36.154846Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2024-06-19T21:47:36.722764Z","iopub.execute_input":"2024-06-19T21:47:36.723114Z","iopub.status.idle":"2024-06-19T21:47:36.738110Z","shell.execute_reply.started":"2024-06-19T21:47:36.723085Z","shell.execute_reply":"2024-06-19T21:47:36.737239Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                        img_path     label\n4315  /kaggle/working/AM1914.jpg  3.383333\n1832   /kaggle/working/CF376.jpg  2.450000\n3819   /kaggle/working/CM191.jpg  2.983333\n957   /kaggle/working/AM1298.jpg  2.616667\n3545   /kaggle/working/AF966.jpg  3.033333\n...                          ...       ...\n3772  /kaggle/working/AF1082.jpg  2.633333\n5191  /kaggle/working/AM1877.jpg  4.033333\n5226   /kaggle/working/CF206.jpg  2.133333\n5390   /kaggle/working/AM959.jpg  2.083333\n860   /kaggle/working/AM1977.jpg  4.083333\n\n[4400 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>img_path</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4315</th>\n      <td>/kaggle/working/AM1914.jpg</td>\n      <td>3.383333</td>\n    </tr>\n    <tr>\n      <th>1832</th>\n      <td>/kaggle/working/CF376.jpg</td>\n      <td>2.450000</td>\n    </tr>\n    <tr>\n      <th>3819</th>\n      <td>/kaggle/working/CM191.jpg</td>\n      <td>2.983333</td>\n    </tr>\n    <tr>\n      <th>957</th>\n      <td>/kaggle/working/AM1298.jpg</td>\n      <td>2.616667</td>\n    </tr>\n    <tr>\n      <th>3545</th>\n      <td>/kaggle/working/AF966.jpg</td>\n      <td>3.033333</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3772</th>\n      <td>/kaggle/working/AF1082.jpg</td>\n      <td>2.633333</td>\n    </tr>\n    <tr>\n      <th>5191</th>\n      <td>/kaggle/working/AM1877.jpg</td>\n      <td>4.033333</td>\n    </tr>\n    <tr>\n      <th>5226</th>\n      <td>/kaggle/working/CF206.jpg</td>\n      <td>2.133333</td>\n    </tr>\n    <tr>\n      <th>5390</th>\n      <td>/kaggle/working/AM959.jpg</td>\n      <td>2.083333</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>/kaggle/working/AM1977.jpg</td>\n      <td>4.083333</td>\n    </tr>\n  </tbody>\n</table>\n<p>4400 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self,imgs_path,labels,transforms=None):\n        self.imgs_path=imgs_path\n        self.labels=labels\n        self.transforms=transforms\n    def __getitem__(self,index):\n        img_path=self.imgs_path[index]\n        image=cv2.imread(img_path)\n        if self.transforms is not None:\n            image=self.transforms(image=image)['image']\n        if self.labels is not None:\n            label=self.labels[index]\n            return image,label\n        else:\n            return image\n    def __len__(self):\n        return len(self.imgs_path)\ntrain_transform=A.Compose([\n    A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE'],interpolation=cv2.INTER_CUBIC),\n    A.Normalize(mean=(0.485,0.456,0.406),std=(0.229,0.224,0.225)),\n    ToTensorV2()\n])\ntest_transform=A.Compose([\n    A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE'],interpolation=cv2.INTER_CUBIC),\n    A.Normalize(mean=(0.485,0.456,0.406),std=(0.229,0.224,0.225)),\n    ToTensorV2()\n])\ntrain_dataset=CustomDataset(train['img_path'].values,train['label'].values,train_transform)\nval_dataset=CustomDataset(val['img_path'].values,val['label'].values,test_transform)\ntrain_loader=DataLoader(train_dataset,batch_size=CFG['BATCH_SIZE'],shuffle=True,num_workers=0)\nval_loader=DataLoader(val_dataset,batch_size=CFG['BATCH_SIZE'],shuffle=False,num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T21:47:39.893992Z","iopub.execute_input":"2024-06-19T21:47:39.894341Z","iopub.status.idle":"2024-06-19T21:47:39.906619Z","shell.execute_reply.started":"2024-06-19T21:47:39.894312Z","shell.execute_reply":"2024-06-19T21:47:39.905779Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import timm\nmodel=timm.create_model('timm/swinv2_large_window12to16_192to256.ms_in22k_ft_in1k', pretrained=True,num_classes=1)\nmodel = torch.nn.DataParallel(model)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T21:47:41.395534Z","iopub.execute_input":"2024-06-19T21:47:41.396366Z","iopub.status.idle":"2024-06-19T21:47:46.180842Z","shell.execute_reply.started":"2024-06-19T21:47:41.396333Z","shell.execute_reply":"2024-06-19T21:47:46.180047Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error\nimport copy\ndef train(model, optimizer, train_loader, val_loader, scheduler, device, early_stopping_patience=3):\n    criterion = nn.MSELoss().to(device)\n    model.to(device)\n    best_model = None\n    best_loss = float('inf')\n    patience = 0\n\n    for epoch in range(1,CFG['EPOCHS']+1):\n        train_loss = []\n        train_preds, train_score_true = [], []\n        model.train()\n\n        for img, score in tqdm(iter(train_loader)):\n            img = img.float().to(device)\n            score = score.float().to(device)\n            optimizer.zero_grad()\n            output = model(img)\n            loss = criterion(output, score) \n            loss.backward()\n            optimizer.step()\n\n            train_loss.append(loss.item())\n            train_preds += output.detach().cpu().numpy().tolist()  \n            train_score_true += score.detach().cpu().numpy().tolist()\n        _train_loss=np.mean(train_loss)\n        _train_mae = mean_absolute_error(train_score_true, train_preds)\n        _val_mae, _val_loss= validation(model, val_loader, criterion, device)\n        current_lr = optimizer.param_groups[0]['lr']\n\n        print(f'Epoch [{epoch}], Train MAE: [{_train_mae:.5f}], Train Loss: [{_train_loss:.5f}], Val MAE: [{_val_mae:.5f}], Val Loss: [{_val_loss:.5f}], Learning Rate: {current_lr}')\n\n        if scheduler is not None:\n            scheduler.step()\n\n        if best_loss > _val_mae:\n            best_loss = _val_mae\n            best_model = copy.deepcopy(model)\n            torch.save(best_model, 'swinv2_age.pt')\n            patience = 0\n        else:\n            patience += 1\n\n        if patience >= early_stopping_patience:\n            print(f'Early stopping triggered at epoch {epoch}!')\n            break\n\n    return best_model\n\ndef validation(model, val_loader, criterion, device):\n    model.eval()\n    val_loss = []\n    val_preds, val_score_true = [], []\n\n    with torch.no_grad():\n        for img, score in tqdm(iter(val_loader)):\n            img = img.float().to(device)\n            score= score.float().to(device)\n            pred = model(img)\n            loss = criterion(pred, score)  # pred를 squeeze하여 차원을 맞춤\n\n            val_preds += pred.detach().cpu().numpy().tolist()  # flatten을 사용하여 1차원 배열로 변환\n            val_score_true += score.detach().cpu().numpy().tolist()\n            val_loss.append(loss.item())\n        _val_loss=np.mean(val_loss)\n        _val_mae = mean_absolute_error(val_score_true, val_preds)\n\n    return _val_mae, _val_loss","metadata":{"execution":{"iopub.status.busy":"2024-06-19T22:14:20.507774Z","iopub.execute_input":"2024-06-19T22:14:20.508172Z","iopub.status.idle":"2024-06-19T22:14:20.525521Z","shell.execute_reply.started":"2024-06-19T22:14:20.508141Z","shell.execute_reply":"2024-06-19T22:14:20.524479Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model.eval()\noptimizer=torch.optim.AdamW(params=model.parameters(),lr=CFG['LEARNING_RATE'])\nscheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=10)\ninfer_model=train(model,optimizer,train_loader,val_loader,scheduler,device)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T22:14:20.773215Z","iopub.execute_input":"2024-06-19T22:14:20.773568Z","iopub.status.idle":"2024-06-19T22:54:07.413013Z","shell.execute_reply.started":"2024-06-19T22:14:20.773539Z","shell.execute_reply":"2024-06-19T22:54:07.412015Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 275/275 [07:23<00:00,  1.61s/it]\n100%|██████████| 69/69 [00:33<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1], Train MAE: [0.55607], Train Loss: [0.48700], Val MAE: [0.58232], Val Loss: [0.49086], Learning Rate: 1e-05\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 275/275 [07:24<00:00,  1.62s/it]\n100%|██████████| 69/69 [00:33<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2], Train MAE: [0.55519], Train Loss: [0.49135], Val MAE: [0.54555], Val Loss: [0.47732], Learning Rate: 9.755282581475769e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 275/275 [07:22<00:00,  1.61s/it]\n100%|██████████| 69/69 [00:33<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3], Train MAE: [0.55324], Train Loss: [0.48348], Val MAE: [0.56918], Val Loss: [0.47537], Learning Rate: 9.045084971874738e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 275/275 [07:21<00:00,  1.61s/it]\n100%|██████████| 69/69 [00:33<00:00,  2.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4], Train MAE: [0.54853], Train Loss: [0.48206], Val MAE: [0.54670], Val Loss: [0.48074], Learning Rate: 7.938926261462366e-06\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 275/275 [07:22<00:00,  1.61s/it]\n100%|██████████| 69/69 [00:33<00:00,  2.05it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [5], Train MAE: [0.54710], Train Loss: [0.47955], Val MAE: [0.55262], Val Loss: [0.47409], Learning Rate: 6.545084971874738e-06\nEarly stopping triggered at epoch 5!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch, gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor i in df['img_path']:\n    os.remove(i)","metadata":{"execution":{"iopub.status.busy":"2024-06-19T23:00:26.022613Z","iopub.execute_input":"2024-06-19T23:00:26.022980Z","iopub.status.idle":"2024-06-19T23:00:26.213071Z","shell.execute_reply.started":"2024-06-19T23:00:26.022952Z","shell.execute_reply":"2024-06-19T23:00:26.212048Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}